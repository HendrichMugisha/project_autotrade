{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531b8914-d693-46e1-ba2c-13d44af3d7fb",
   "metadata": {},
   "source": [
    "### Focus: The \"Kitchen Sink\" (Aggressive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a9a70-06a4-4e27-9c44-eb10ce83363f",
   "metadata": {},
   "source": [
    "### 1.Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18a21588-fb3b-497b-8aee-8c3369bbf901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data\\triple_barrier_16h.parquet...\n",
      "Initial Shape: (9301, 12)\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. CONFIGURATION\n",
    "# choosing 16 as it had the most well balanced dataset\n",
    "INPUT_FILENAME = \"triple_barrier_16h.parquet\" \n",
    "INPUT_PATH = os.path.join('../data', INPUT_FILENAME)\n",
    "OUTPUT_FILENAME = \"engineered_features_16h.parquet\"\n",
    "OUTPUT_PATH = os.path.join('../data', OUTPUT_FILENAME)\n",
    "\n",
    "# 2. LOAD DATA\n",
    "print(f\"Loading data from {INPUT_PATH}...\")\n",
    "df = pd.read_parquet(INPUT_PATH)\n",
    "\n",
    "# Ensure index is datetime\n",
    "if not isinstance(df.index, pd.DatetimeIndex):\n",
    "    # if not then simply convert it\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "print(f\"Initial Shape: {df.shape}\")\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be3ffd42-4990-4f9f-b369-18c7ee3dbaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9301, 12)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7706b-800b-4270-b626-8d8b0dfcb6e2",
   "metadata": {},
   "source": [
    "### 2: Time Standardization (UTC+2 -> UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70038322-9ac1-4452-92db-dac98945b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting time from UTC+2 to UTC...\n",
      "New start time (UTC): 2020-01-06 06:00:00\n",
      "New end time (UTC): 2025-12-24 02:00:00\n"
     ]
    }
   ],
   "source": [
    "# 1. STANDARDIZE TIMEZONE\n",
    "# Data is UTC+2 (Broker Time). We subtract 2 hours to get true UTC.\n",
    "print(\"Shifting time from UTC+2 to UTC...\")\n",
    "\n",
    "# this is a fancy operation to remove 2 hours and hence convert the timeframt to utc\n",
    "df.index = df.index - pd.Timedelta(hours=2)\n",
    "\n",
    "# Verify the shift (Optional check)\n",
    "# If it was 10:00 Broker time, it should now be 08:00 UTC (London Open)\n",
    "print(f\"New start time (UTC): {df.index[0]}\")\n",
    "print(f\"New end time (UTC): {df.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d7f93-abdc-4ef3-9d31-c6eca1cb6845",
   "metadata": {},
   "source": [
    "### 3. Aggressive Technical & Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7582d3-cf7d-4115-bc14-cf00b6c94f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features...\n",
      "Spread features added.\n",
      "Volume features added using column: tick_volume\n",
      "Feature Engineering Complete.\n",
      "Dropped 200 rows (warmup).\n",
      "Final Feature Count: 53\n"
     ]
    }
   ],
   "source": [
    "# # Create a copy to work on like a nroaml person\n",
    "# df_feat = df.copy()\n",
    "\n",
    "# print(\"Generating features...\")\n",
    "\n",
    "# # ==========================================\n",
    "# # 1. TIME & SESSION CONTEXT\n",
    "# # ==========================================\n",
    "# # Cyclical Time (Clock Coordinates)\n",
    "\n",
    "\n",
    "# # We use Sine and Cosine to map the hours onto a circle. Now,\n",
    "# # 11 PM and Midnight are mathematically close to each other\n",
    "\n",
    "# df_feat['hour_sin'] = np.sin(2 * np.pi * df_feat.index.hour / 24)\n",
    "# df_feat['hour_cos'] = np.cos(2 * np.pi * df_feat.index.hour / 24)\n",
    "# df_feat['day_sin'] = np.sin(2 * np.pi * df_feat.index.dayofweek / 7)\n",
    "# df_feat['day_cos'] = np.cos(2 * np.pi * df_feat.index.dayofweek / 7)\n",
    "\n",
    "# # Session Booleans (Based on UTC)\n",
    "# h = df_feat.index.hour\n",
    "# df_feat['sess_london'] = ((h >= 7) & (h <= 16)).astype(int)\n",
    "# df_feat['sess_ny'] = ((h >= 12) & (h <= 21)).astype(int)\n",
    "# df_feat['sess_tokyo'] = ((h >= 0) & (h <= 9)).astype(int)\n",
    "# df_feat['sess_sydney'] = ((h >= 21) | (h <= 6)).astype(int) # Wraps midnight\n",
    "\n",
    "# # Critical Overlaps & Zones\n",
    "# df_feat['sess_london_ny'] = (df_feat['sess_london'] & df_feat['sess_ny']).astype(int)\n",
    "# df_feat['sess_tokyo_london'] = (df_feat['sess_tokyo'] & df_feat['sess_london']).astype(int)\n",
    "\n",
    "# # The US banks are closed, and Tokyo hasn't opened fully. Spreads widen, and moves are often fake.\n",
    "# df_feat['sess_dead_zone'] = ((h >= 21) | (h == 0)).astype(int) # Late NY / Early Syd\n",
    "\n",
    "# # The market literally goes to lunch. Volume drops to zero.\n",
    "# df_feat['sess_asian_lunch'] = ((h >= 3) & (h <= 4)).astype(int) # Low Volatility\n",
    "\n",
    "# # ==========================================\n",
    "# # 2. MARKET MICROSTRUCTURE (Spread & Vol)\n",
    "# # ==========================================\n",
    "# # Spread Features (Liquidity Risk)\n",
    "# if 'spread' in df_feat.columns:\n",
    "#     # Normalize spread by price (e.g., 0.0001 / 1.1000)\n",
    "#     df_feat['spread_pct'] = df_feat['spread'] / df_feat['close']\n",
    "#     # Spread Shock: Is spread currently 2x or 3x the average? (News Event Detector)\n",
    "#     df_feat['spread_shock'] = df_feat['spread'] / df_feat['spread'].rolling(20).mean()\n",
    "#     print(\"Spread features added.\")\n",
    "\n",
    "\n",
    "# # Volume Features (Activity)\n",
    "# vol_col = 'tick_volume' if 'tick_volume' in df_feat.columns else 'volume' if 'volume' in df_feat.columns else None\n",
    "\n",
    "# if vol_col:\n",
    "\n",
    "#     # Price moves up + Low Volume: The car is coasting uphill. It will likely roll back (False Breakout).\n",
    "#     df_feat['vol_rel'] = df_feat[vol_col] / df_feat[vol_col].rolling(20).mean()\n",
    "    \n",
    "#     # Force volume stationarity (Rate of Change)\n",
    "#     df_feat['vol_roc'] = df_feat[vol_col].pct_change()\n",
    "#     print(f\"Volume features added using column: {vol_col}\")\n",
    "\n",
    "# # ==========================================\n",
    "# # 3. VOLATILITY & STATS\n",
    "# # ==========================================\n",
    "# # Bollinger Bands\n",
    "# sma_20 = df_feat['close'].rolling(20).mean()\n",
    "# std_20 = df_feat['close'].rolling(20).std()\n",
    "# bb_upper = sma_20 + (std_20 * 2)\n",
    "# bb_lower = sma_20 - (std_20 * 2)\n",
    "\n",
    "# # o measure if the market is \"nervous\" (volatile) or \"calm\", \n",
    "# # and if price is \"stretched\" (likely to snap back).\n",
    "# df_feat['bb_width'] = (bb_upper - bb_lower) / sma_20 # Squeeze/Expand\n",
    "# df_feat['bb_pos'] = (df_feat['close'] - bb_lower) / (bb_upper - bb_lower) # Position\n",
    "\n",
    "\n",
    "\n",
    "# # Rolling Distribution Shape (The \"Aggressive\" Stats)\n",
    "# # Intuition (The Shape of Danger):\n",
    "\n",
    "# for window in [20, 50]:\n",
    "#     # Is the market crashing up or crashing down?\n",
    "#     df_feat[f'roll_skew_{window}'] = df_feat['close'].rolling(window).skew()\n",
    "#     # High kurtosis means the market is jumpy and dangerous.\n",
    "#     df_feat[f'roll_kurt_{window}'] = df_feat['close'].rolling(window).kurt()\n",
    "\n",
    "# # ATR % (if ATR exists from labelling)\n",
    "# if 'atr' in df_feat.columns:\n",
    "#     df_feat['atr_pct'] = df_feat['atr'] / df_feat['close']\n",
    "\n",
    "# # ==========================================\n",
    "# # 4. MOMENTUM & TREND (Stationary)\n",
    "# # ==========================================\n",
    "# # RSI\n",
    "# # Intuition (The Speedometer): How fast is price changing? If RSI > 70, the engine is redlining.\n",
    "\n",
    "# for window in [7, 14, 21]:\n",
    "#     delta = df_feat['close'].diff()\n",
    "#     gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "#     loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "#     rs = gain / loss\n",
    "#     df_feat[f'rsi_{window}'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# # MACD\n",
    "# ema_12 = df_feat['close'].ewm(span=12, adjust=False).mean()\n",
    "# ema_26 = df_feat['close'].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "# # \"Are the short-term and long-term trends agreeing or fighting?\"\n",
    "# df_feat['macd_hist'] = (ema_12 - ema_26) - (ema_12 - ema_26).ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# # Distance from Moving Averages (Trend Strength)\n",
    "# for period in [20, 50, 100, 200]:\n",
    "#     ma = df_feat['close'].rolling(period).mean()\n",
    "#     df_feat[f'dist_sma_{period}'] = (df_feat['close'] - ma) / ma\n",
    "#     df_feat[f'slope_sma_{period}'] = ma.diff()\n",
    "\n",
    "# # ==========================================\n",
    "# # 5. LAGS (Memory)\n",
    "# # ==========================================\n",
    "# # Log returns of previous candles\n",
    "# for lag in [1, 2, 3, 5, 8, 13]:\n",
    "#     df_feat[f'log_ret_lag_{lag}'] = np.log(df_feat['close'] / df_feat['close'].shift(lag))\n",
    "\n",
    "# # Cleanup\n",
    "# # Drop rows with NaN (Warmup period for 200 SMA)\n",
    "# original_len = len(df_feat)\n",
    "# df_feat.dropna(inplace=True)\n",
    "\n",
    "# print(\"Feature Engineering Complete.\")\n",
    "# print(f\"Dropped {original_len - len(df_feat)} rows (warmup).\")\n",
    "# print(f\"Final Feature Count: {df_feat.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e75c15-e8b8-4a34-876e-75692bce6b7d",
   "metadata": {},
   "source": [
    "### Save Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f804d7b1-0112-4d04-affd-c1cb37869969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data to ../data\\engineered_features_16h.parquet...\n",
      "\n",
      "--- Feature List ---\n",
      "['open', 'high', 'low', 'close', 'tick_volume', 'spread', 'h-l', 'h-pc', 'l-pc', 'tr', 'atr', 'label', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'sess_london', 'sess_ny', 'sess_tokyo', 'sess_sydney', 'sess_london_ny', 'sess_tokyo_london', 'sess_dead_zone', 'sess_asian_lunch', 'spread_pct', 'spread_shock', 'vol_rel', 'vol_roc', 'bb_width', 'bb_pos', 'roll_skew_20', 'roll_kurt_20', 'roll_skew_50', 'roll_kurt_50', 'atr_pct', 'rsi_7', 'rsi_14', 'rsi_21', 'macd_hist', 'dist_sma_20', 'slope_sma_20', 'dist_sma_50', 'slope_sma_50', 'dist_sma_100', 'slope_sma_100', 'dist_sma_200', 'slope_sma_200', 'log_ret_lag_1', 'log_ret_lag_2', 'log_ret_lag_3', 'log_ret_lag_5', 'log_ret_lag_8', 'log_ret_lag_13']\n",
      "\n",
      "--- Sample Data (Last 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>spread</th>\n",
       "      <th>h-l</th>\n",
       "      <th>h-pc</th>\n",
       "      <th>l-pc</th>\n",
       "      <th>tr</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_sma_100</th>\n",
       "      <th>slope_sma_100</th>\n",
       "      <th>dist_sma_200</th>\n",
       "      <th>slope_sma_200</th>\n",
       "      <th>log_ret_lag_1</th>\n",
       "      <th>log_ret_lag_2</th>\n",
       "      <th>log_ret_lag_3</th>\n",
       "      <th>log_ret_lag_5</th>\n",
       "      <th>log_ret_lag_8</th>\n",
       "      <th>log_ret_lag_13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-12-23 10:00:00</th>\n",
       "      <td>1.17925</td>\n",
       "      <td>1.18018</td>\n",
       "      <td>1.17741</td>\n",
       "      <td>1.17746</td>\n",
       "      <td>9584</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>-0.001519</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.005322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-23 14:00:00</th>\n",
       "      <td>1.17747</td>\n",
       "      <td>1.17803</td>\n",
       "      <td>1.17639</td>\n",
       "      <td>1.17707</td>\n",
       "      <td>12337</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00164</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>0.00164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>-0.000331</td>\n",
       "      <td>-0.001850</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.004376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-23 18:00:00</th>\n",
       "      <td>1.17707</td>\n",
       "      <td>1.17968</td>\n",
       "      <td>1.17695</td>\n",
       "      <td>1.17933</td>\n",
       "      <td>4971</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00273</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.006303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-23 22:00:00</th>\n",
       "      <td>1.17897</td>\n",
       "      <td>1.18063</td>\n",
       "      <td>1.17894</td>\n",
       "      <td>1.18051</td>\n",
       "      <td>4260</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.00169</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.00169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-24 02:00:00</th>\n",
       "      <td>1.18053</td>\n",
       "      <td>1.18079</td>\n",
       "      <td>1.17857</td>\n",
       "      <td>1.17990</td>\n",
       "      <td>4235</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.00194</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.006948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close  tick_volume  spread  \\\n",
       "time                                                                           \n",
       "2025-12-23 10:00:00  1.17925  1.18018  1.17741  1.17746         9584    8.00   \n",
       "2025-12-23 14:00:00  1.17747  1.17803  1.17639  1.17707        12337    8.00   \n",
       "2025-12-23 18:00:00  1.17707  1.17968  1.17695  1.17933         4971    8.00   \n",
       "2025-12-23 22:00:00  1.17897  1.18063  1.17894  1.18051         4260   12.75   \n",
       "2025-12-24 02:00:00  1.18053  1.18079  1.17857  1.17990         4235    8.00   \n",
       "\n",
       "                         h-l     h-pc     l-pc       tr  ...  dist_sma_100  \\\n",
       "time                                                     ...                 \n",
       "2025-12-23 10:00:00  0.00277  0.00093  0.00184  0.00277  ...      0.007084   \n",
       "2025-12-23 14:00:00  0.00164  0.00057  0.00107  0.00164  ...      0.006607   \n",
       "2025-12-23 18:00:00  0.00273  0.00261  0.00012  0.00273  ...      0.008372   \n",
       "2025-12-23 22:00:00  0.00169  0.00130  0.00039  0.00169  ...      0.009223   \n",
       "2025-12-24 02:00:00  0.00222  0.00028  0.00194  0.00222  ...      0.008568   \n",
       "\n",
       "                     slope_sma_100  dist_sma_200  slope_sma_200  \\\n",
       "time                                                              \n",
       "2025-12-23 10:00:00       0.000178      0.012351       0.000132   \n",
       "2025-12-23 14:00:00       0.000166      0.011904       0.000129   \n",
       "2025-12-23 18:00:00       0.000196      0.013735       0.000129   \n",
       "2025-12-23 22:00:00       0.000183      0.014634       0.000132   \n",
       "2025-12-24 02:00:00       0.000154      0.013999       0.000126   \n",
       "\n",
       "                     log_ret_lag_1  log_ret_lag_2  log_ret_lag_3  \\\n",
       "time                                                               \n",
       "2025-12-23 10:00:00      -0.001519      -0.000025       0.000144   \n",
       "2025-12-23 14:00:00      -0.000331      -0.001850      -0.000357   \n",
       "2025-12-23 18:00:00       0.001918       0.001587       0.000068   \n",
       "2025-12-23 22:00:00       0.001000       0.002918       0.002587   \n",
       "2025-12-24 02:00:00      -0.000517       0.000483       0.002401   \n",
       "\n",
       "                     log_ret_lag_5  log_ret_lag_8  log_ret_lag_13  \n",
       "time                                                               \n",
       "2025-12-23 10:00:00       0.001402       0.004878        0.005322  \n",
       "2025-12-23 14:00:00       0.000841       0.003472        0.004376  \n",
       "2025-12-23 18:00:00       0.001731       0.003636        0.006303  \n",
       "2025-12-23 22:00:00       0.002561       0.003989        0.008174  \n",
       "2025-12-24 02:00:00       0.000551       0.003243        0.006948  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Save to Parquet\n",
    "print(f\"Saving processed data to {OUTPUT_PATH}...\")\n",
    "df_feat.to_parquet(OUTPUT_PATH, index=True)\n",
    "\n",
    "# 2. Sanity Check: Inspect the Columns\n",
    "print(\"\\n--- Feature List ---\")\n",
    "print(df_feat.columns.tolist())\n",
    "\n",
    "print(\"\\n--- Sample Data (Last 5 rows) ---\")\n",
    "df_feat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c56f67-2575-4c01-b673-5e6c6766d4c4",
   "metadata": {},
   "source": [
    "### to be tried later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85455446-ad61-40b5-bd61-9b49f7b21ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b44742-f7ff-49e7-ba5f-c2df31ab6e2a",
   "metadata": {},
   "source": [
    "### TRYING OUT THE NEW FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f7093fa-0fb8-4ee2-ac51-799dca61d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape: (9301, 12)\n",
      "Calculating Indicators...\n",
      "Stationarizing...\n",
      "\n",
      "--- DIAGNOSTIC REPORT ---\n",
      "Total Rows: 9301\n",
      "NaN Count per Column (High numbers here are the killers):\n",
      "label              0\n",
      "ADX_14          9301\n",
      "Aroon_Up          25\n",
      "Aroon_Down        25\n",
      "RSI_14             1\n",
      "MACD               0\n",
      "MACD_Signal        0\n",
      "STOCH_k           13\n",
      "CCI_20            19\n",
      "WILLR             13\n",
      "OBV                0\n",
      "CMF               19\n",
      "MFI             9301\n",
      "dist_ema_50        0\n",
      "dist_ema_200       0\n",
      "dist_psar          0\n",
      "kc_pos             0\n",
      "bb_pos            19\n",
      "NATR               0\n",
      "dtype: int64\n",
      "\n",
      "CRITICAL: These columns are 100% empty and will be dropped: ['ADX_14', 'MFI']\n",
      "\n",
      "Final Shape after cleanup: (9276, 17)\n",
      "Success! Data is ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. HELPER FUNCTIONS (UNCHANGED)\n",
    "# ==========================================\n",
    "def calculate_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_atr(df, period=14):\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    return tr.ewm(alpha=1/period, adjust=False).mean()\n",
    "\n",
    "def calculate_adx(df, period=14):\n",
    "    tr = calculate_atr(df, period=1)\n",
    "    up_move = df['high'] - df['high'].shift()\n",
    "    down_move = df['low'].shift() - df['low']\n",
    "    plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0)\n",
    "    minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0)\n",
    "    \n",
    "    tr_smooth = pd.Series(tr).ewm(alpha=1/period, adjust=False).mean()\n",
    "    # SAFETY: Avoid divide by zero if TR is 0\n",
    "    tr_smooth = tr_smooth.replace(0, np.nan) \n",
    "    \n",
    "    plus_di = 100 * (pd.Series(plus_dm).ewm(alpha=1/period, adjust=False).mean() / tr_smooth)\n",
    "    minus_di = 100 * (pd.Series(minus_dm).ewm(alpha=1/period, adjust=False).mean() / tr_smooth)\n",
    "    \n",
    "    dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di)\n",
    "    adx = dx.ewm(alpha=1/period, adjust=False).mean()\n",
    "    return adx\n",
    "\n",
    "def calculate_psar(df, af_start=0.02, af_inc=0.02, af_max=0.2):\n",
    "    high = df['high'].values\n",
    "    low = df['low'].values\n",
    "    close = df['close'].values\n",
    "    psar = np.zeros(len(df))\n",
    "    trend = 1 if close[0] > close[1] else -1 \n",
    "    af = af_start\n",
    "    ep = high[0] if trend == 1 else low[0]\n",
    "    psar[0] = low[0] if trend == 1 else high[0]\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        prev_psar = psar[i-1]\n",
    "        psar[i] = prev_psar + af * (ep - prev_psar)\n",
    "        \n",
    "        if trend == 1:\n",
    "            psar[i] = min(psar[i], low[i-1])\n",
    "            if i > 1: psar[i] = min(psar[i], low[i-2])\n",
    "        else:\n",
    "            psar[i] = max(psar[i], high[i-1])\n",
    "            if i > 1: psar[i] = max(psar[i], high[i-2])\n",
    "            \n",
    "        reverse = False\n",
    "        if trend == 1 and low[i] < psar[i]:\n",
    "            trend = -1\n",
    "            psar[i] = ep\n",
    "            ep = low[i]\n",
    "            af = af_start\n",
    "            reverse = True\n",
    "        elif trend == -1 and high[i] > psar[i]:\n",
    "            trend = 1\n",
    "            psar[i] = ep\n",
    "            ep = high[i]\n",
    "            af = af_start\n",
    "            reverse = True\n",
    "        if not reverse:\n",
    "            if trend == 1:\n",
    "                if high[i] > ep:\n",
    "                    ep = high[i]\n",
    "                    af = min(af + af_inc, af_max)\n",
    "            else:\n",
    "                if low[i] < ep:\n",
    "                    ep = low[i]\n",
    "                    af = min(af + af_inc, af_max)\n",
    "    return pd.Series(psar, index=df.index)\n",
    "\n",
    "def calculate_aroon(df, period=25):\n",
    "    aroon_up = df['high'].rolling(period + 1).apply(lambda x: x.argmax(), raw=True) / period * 100\n",
    "    aroon_down = df['low'].rolling(period + 1).apply(lambda x: x.argmin(), raw=True) / period * 100\n",
    "    return aroon_up, aroon_down\n",
    "\n",
    "# ==========================================\n",
    "# 2. DIAGNOSTIC EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "print(f\"Initial Shape: {df.shape}\")\n",
    "\n",
    "# A. Volume Check\n",
    "if 'tick_volume' in df.columns:\n",
    "    df['volume'] = df['tick_volume']\n",
    "elif 'Volume' in df.columns:\n",
    "    df['volume'] = df['Volume']\n",
    "else:\n",
    "    print(\"CRITICAL WARNING: No Volume column found! Creating dummy volume (1).\")\n",
    "    df['volume'] = 1\n",
    "\n",
    "# B. Calculate Indicators\n",
    "print(\"Calculating Indicators...\")\n",
    "try:\n",
    "    df['EMA_50'] = df['close'].ewm(span=50, adjust=False).mean()\n",
    "    df['EMA_200'] = df['close'].ewm(span=200, adjust=False).mean()\n",
    "    df['PSAR'] = calculate_psar(df)\n",
    "    df['ADX_14'] = calculate_adx(df)\n",
    "    df['Aroon_Up'], df['Aroon_Down'] = calculate_aroon(df)\n",
    "    df['RSI_14'] = calculate_rsi(df['close'])\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema12 - ema26\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # Stoch & CCI\n",
    "    low_min = df['low'].rolling(14).min()\n",
    "    high_max = df['high'].rolling(14).max()\n",
    "    # Fix division by zero if High == Low\n",
    "    denom = (high_max - low_min).replace(0, np.nan)\n",
    "    df['STOCH_k'] = 100 * (df['close'] - low_min) / denom\n",
    "    \n",
    "    tp = (df['high'] + df['low'] + df['close']) / 3\n",
    "    df['CCI_20'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
    "    df['WILLR'] = -100 * (high_max - df['close']) / denom\n",
    "    \n",
    "    # Volatility\n",
    "    df['ATR_14'] = calculate_atr(df)\n",
    "    df['BBL_20'] = df['close'].rolling(20).mean() - 2 * df['close'].rolling(20).std()\n",
    "    df['BBU_20'] = df['close'].rolling(20).mean() + 2 * df['close'].rolling(20).std()\n",
    "    df['KC_Upper'] = df['EMA_50'] + 2 * df['ATR_14'] \n",
    "    df['KC_Lower'] = df['EMA_50'] - 2 * df['ATR_14']\n",
    "\n",
    "    # Volume Indicators\n",
    "    df['OBV'] = (np.sign(df['close'].diff()) * df['volume']).fillna(0).cumsum()\n",
    "    \n",
    "    mf_multiplier = ((df['close'] - df['low']) - (df['high'] - df['close'])) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "    mf_vol = mf_multiplier.fillna(0) * df['volume']\n",
    "    df['CMF'] = mf_vol.rolling(20).sum() / df['volume'].rolling(20).sum().replace(0, np.nan)\n",
    "    \n",
    "    typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "    raw_money_flow = typical_price * df['volume']\n",
    "    positive_flow = np.where(typical_price > typical_price.shift(), raw_money_flow, 0)\n",
    "    negative_flow = np.where(typical_price < typical_price.shift(), raw_money_flow, 0)\n",
    "    mfi_ratio = pd.Series(positive_flow).rolling(14).sum() / pd.Series(negative_flow).rolling(14).sum().replace(0, np.nan)\n",
    "    df['MFI'] = 100 - (100 / (1 + mfi_ratio))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during calculation: {e}\")\n",
    "\n",
    "# C. Stationarization\n",
    "print(\"Stationarizing...\")\n",
    "df['dist_ema_50'] = (df['close'] - df['EMA_50']) / df['EMA_50']\n",
    "df['dist_ema_200'] = (df['close'] - df['EMA_200']) / df['EMA_200']\n",
    "df['dist_psar'] = (df['close'] - df['PSAR']) / df['close']\n",
    "df['kc_pos'] = (df['close'] - df['KC_Lower']) / (df['KC_Upper'] - df['KC_Lower'])\n",
    "df['bb_pos'] = (df['close'] - df['BBL_20']) / (df['BBU_20'] - df['BBL_20'])\n",
    "df['NATR'] = (df['ATR_14'] / df['close']) * 100\n",
    "\n",
    "# ==========================================\n",
    "# 3. THE DIAGNOSTIC REPORT (CRITICAL STEP)\n",
    "# ==========================================\n",
    "\n",
    "# Define columns we WANT to keep\n",
    "keep_cols = [\n",
    "    'label', 'ADX_14', 'Aroon_Up', 'Aroon_Down', 'RSI_14', 'MACD', 'MACD_Signal', \n",
    "    'STOCH_k', 'CCI_20', 'WILLR', 'OBV', 'CMF', 'MFI', \n",
    "    'dist_ema_50', 'dist_ema_200', 'dist_psar', 'kc_pos', 'bb_pos', 'NATR'\n",
    "]\n",
    "\n",
    "# Check only these columns\n",
    "temp_df = df[keep_cols]\n",
    "\n",
    "print(\"\\n--- DIAGNOSTIC REPORT ---\")\n",
    "print(f\"Total Rows: {len(temp_df)}\")\n",
    "print(\"NaN Count per Column (High numbers here are the killers):\")\n",
    "print(temp_df.isna().sum())\n",
    "\n",
    "# Identify columns that are 100% NaN\n",
    "empty_cols = [col for col in temp_df.columns if temp_df[col].isna().all()]\n",
    "if empty_cols:\n",
    "    print(f\"\\nCRITICAL: These columns are 100% empty and will be dropped: {empty_cols}\")\n",
    "    # Remove them from our 'keep' list so we don't kill the whole df\n",
    "    keep_cols = [c for c in keep_cols if c not in empty_cols]\n",
    "\n",
    "# ==========================================\n",
    "# 4. FINAL CLEANUP\n",
    "# ==========================================\n",
    "df_final = df[keep_cols].copy()\n",
    "df_final.dropna(inplace=True)\n",
    "\n",
    "print(f\"\\nFinal Shape after cleanup: {df_final.shape}\")\n",
    "if df_final.shape[0] > 0:\n",
    "    print(\"Success! Data is ready.\")\n",
    "    df = df_final # Assign back to main variable\n",
    "else:\n",
    "    print(\"FAILED: Data is still empty. Check the NaN counts above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6abfaa7-ffde-40d7-ab41-2f6c34ad64e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'Aroon_Up', 'Aroon_Down', 'RSI_14', 'MACD', 'MACD_Signal',\n",
       "       'STOCH_k', 'CCI_20', 'WILLR', 'OBV', 'CMF', 'dist_ema_50',\n",
       "       'dist_ema_200', 'dist_psar', 'kc_pos', 'bb_pos', 'NATR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a88c9-1f0e-4583-afea-a4a113b58902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Trend Indicators (Baselines)\n",
    "# These indicators identify the general direction of the market and help traders \"follow the trend\". \n",
    "# Simple Moving Average (SMA): The average price over a set number of periods.\n",
    "# Exponential Moving Average (EMA): Similar to SMA but weights recent prices more heavily.\n",
    "# Weighted Moving Average (WMA): Assigns heavier weight to the most recent data points.\n",
    "# Hull Moving Average (HMA): Designed to reduce lag and improve smoothness.\n",
    "# Kaufman Adaptive Moving Average (KAMA): Adjusts its sensitivity based on market noise.\n",
    "# Ichimoku Cloud (Kinko Hyo): A comprehensive system showing trend, support, and resistance.\n",
    "# Parabolic SAR (Stop and Reverse): Uses dots to indicate potential trend reversals.\n",
    "# Average Directional Index (ADX): Measures the strength of a trend.\n",
    "# Aroon Indicator: Identifies when a trend is starting or changing.\n",
    "# Aroon Oscillator: Measures the difference between Aroon Up and Aroon Down.\n",
    "# Linear Regression Trendline: A straight line that best fits a set of price data.\n",
    "# Double Exponential Moving Average (DEMA): Further reduces lag from standard EMAs.\n",
    "# Triple Exponential Moving Average (TEMA): Uses triple smoothing to minimize lag.\n",
    "# Supertrend: A trend-following indicator based on ATR.\n",
    "# ZigZag: Filters out smaller price movements to show significant trends.\n",
    "# Schaff Trend Cycle (STC): Combines MACD with a stochastic for faster trend signals.\n",
    "# TRIX: A triple-smoothed exponential oscillator for trend identification.\n",
    "# Detrended Price Oscillator (DPO): Removes trend to highlight short-term cycles.\n",
    "# Alligator (Bill Williams): Uses three smoothed moving averages to identify trends.\n",
    "# Gann Fans/Gann Lines: Based on geometric angles of price and time. \n",
    "\n",
    "# 2. Momentum Indicators (Oscillators)\n",
    "# These measure the speed of price movements and identify overbought or oversold conditions.\n",
    "# 21. Relative Strength Index (RSI): Ranges 0-100; signals overbought (>70) or oversold (<30).\n",
    "# 22. Stochastic Oscillator: Compares closing price to its range over time.\n",
    "# 23. MACD (Moving Average Convergence Divergence): Shows the relationship between two EMAs.\n",
    "# 24. Commodity Channel Index (CCI): Identifies cyclical trends and reversals.\n",
    "# 25. Williams %R: Shows where the current price is relative to the highest high.\n",
    "# 26. Awesome Oscillator (AO): Measures market momentum using 34 and 5-period SMAs.\n",
    "# 27. Momentum Indicator: Measures the rate of change of prices.\n",
    "# 28. Rate of Change (ROC): Calculates the percentage change in price between periods.\n",
    "# 29. Money Flow Index (MFI): Volume-weighted version of RSI.\n",
    "# 30. Relative Vigor Index (RVI): Measures the strength of a trend by comparing closing prices.\n",
    "# 31. Stochastic RSI: A stochastic applied to RSI values for increased sensitivity.\n",
    "# 32. Ultimate Oscillator: Uses three different timeframes to reduce false signals.\n",
    "# 33. Chande Momentum Oscillator (CMO): Calculates momentum based on unsmoothed data.\n",
    "# 34. Gator Oscillator: Derived from the Alligator indicator to show trend changes.\n",
    "# 35. DeMarker (DeM): Compares most recent maximum and minimum prices.\n",
    "# 36. True Strength Index (TSI): A double-smoothed momentum oscillator.\n",
    "# 37. Vortex Indicator: Two lines (+VI and -VI) that identify the start of a new trend.\n",
    "# 38. Fisher Transform: Transforms prices into a Gaussian normal distribution.\n",
    "# 39. Center of Gravity Oscillator: Identifies major turning points without lag.\n",
    "# 40. Percentage Price Oscillator (PPO): Similar to MACD but shown in percentages. \n",
    "\n",
    "# 3. Volatility Indicators\n",
    "# These measure how far price stretches from its mean, helping with risk management and breakout detection.\n",
    "# 41. Bollinger Bands: A moving average with two standard deviation bands.\n",
    "# 42. Average True Range (ATR): Measures the average range of price movement.\n",
    "# 43. Standard Deviation: Measures how spread out price data is from the mean.\n",
    "# 44. Keltner Channels: Volatility-based envelopes set above/below an EMA.\n",
    "# 45. Donchian Channels: Shows the highest high and lowest low over a period.\n",
    "# 46. Envelopes: Two moving averages set at a fixed percentage above and below price.\n",
    "# 47. Chaikin Volatility: Measures the difference between high and low prices.\n",
    "# 48. Bollinger Bandwidth: Measures the distance between upper and lower Bollinger Bands.\n",
    "# 49. STARC Bands: Combines moving averages and ATR to create volatility channels.\n",
    "# 50. Ulcer Index: Measures \"stress\" by analyzing the depth and duration of price drops.\n",
    "# 51. Relative Volatility Index (RVI): Measures the direction of volatility.\n",
    "# 52. Choppiness Index: Determines if the market is trending or \"choppy\".\n",
    "# 53. Mass Index: Predicts reversals by measuring the narrowing/widening of price ranges.\n",
    "# 54. Historical Volatility (HV): Measures the past standard deviation of an asset. \n",
    "    \n",
    "#     4. Volume & Support/Resistance Indicators\n",
    "# These measure market participation and key price levels.\n",
    "# 55. On-Balance Volume (OBV): Relates volume to price change to confirm trends.\n",
    "# 56. Accumulation/Distribution (A/D): Measures the cumulative flow of money.\n",
    "# 57. Chaikin Money Flow (CMF): Measures the amount of Money Flow Volume over a period.\n",
    "# 58. Volume Weighted Average Price (VWAP): Average price weighted by total volume.\n",
    "# 59. Pivot Points (Standard): Key levels calculated from the previous day's H/L/C.\n",
    "# 60. Fibonacci Retracements: Horizontal lines based on Fibonacci ratios to find support.\n",
    "# 61. Volume Profile: Shows volume traded at specific price levels.\n",
    "# 62. Ease of Movement (EOM): Relates price change to volume.\n",
    "# 63. Money Flow Ratio: Compares positive and negative money flow.\n",
    "# 64. Negative Volume Index (NVI): Focuses on days where volume decreased.\n",
    "# 65. Positive Volume Index (PVI): Focuses on days where volume increased.\n",
    "# 66. Price Volume Trend (PVT): Cumulative volume that adds a percentage of the day's volume.\n",
    "# 67. Trade Volume Index (TVI): Used to determine whether an asset is being accumulated.\n",
    "# 68. Market Profile: Visualizes price and volume over time (TPO).\n",
    "# 69. Balance of Power (BOP): Measures the strength of buyers vs. sellers.\n",
    "# 70. Camarilla Pivot Points: A variation of pivots providing tighter support/resistance.\n",
    "# 71. Woodie’s Pivot Points: Weighted differently to emphasize recent price action.\n",
    "# 72. Fibonacci Extensions: Projects potential future profit-taking levels.\n",
    "# 73. Elder Force Index: Combines price movement and volume to measure trend power.\n",
    "# 74. Vortex Indicator (VI): Identifies the start of a trend based on high/low distance.\n",
    "# 75. Chaikin Oscillator: Applies MACD to the Accumulation/Distribution line.\n",
    "# 76. Force Index: Uses price, volume, and time to identify trend strength.\n",
    "# 77. Klinger Oscillator: Compares volume flowing through an asset with price\n",
    "\n",
    "# 5. Specialized & Hybrid Indicators\n",
    "# Fractals (Bill Williams): Arrows that highlight local high and low points.\n",
    "# Heiken Ashi: Specialized candlesticks that filter market noise.\n",
    "# TD Sequential: Identifies trend exhaustion and potential price flips.\n",
    "# Murrey Math Lines: Support/resistance levels based on Gann's theory.\n",
    "# Psychological Line: Measures the ratio of rising days to total days.\n",
    "# Volume Rate of Change (VROC): Percentage change in volume.\n",
    "# Typical Price: (High + Low + Close) / 3.\n",
    "# Median Price: (High + Low) / 2.\n",
    "# Adaptive Lagging Line: Follows price but smooths out data without excessive lag.\n",
    "# Trend Intensity Index (TII): Measures the strength of a trend.\n",
    "# Rainbow Moving Average: Multiple MAs used together to show trend maturity.\n",
    "# Linear Regression Slope: Measures the rate of change of a linear regression line.\n",
    "# CVI (Chart Volatility Index): A custom measure of intraday volatility.\n",
    "# Gpivot Ressup: Dynamic support and resistance pivot variation.\n",
    "# DMI (Directional Movement Index): Consists of +DI and -DI lines.\n",
    "# TMA (Triangular Moving Average): Double-smoothed version of the SMA.\n",
    "# QQE (Quantitative Qualitative Estimation): Smother RSI-based indicator.\n",
    "# RSX (Relative Strength Index smoothed): A noise-free version of RSI.\n",
    "# ATR Trailing Stop: A stop-loss level that moves with the price.\n",
    "# Connors RSI: Combines RSI, Up/Down Length, and Rate of Change.\n",
    "# Forex Sentiment: Measures the percentage of long vs. short retail positions.\n",
    "# Currency Strength Meter: Compares one currency's performance against all others.\n",
    "# Market Sessions Indicator: Highlights Asian, London, and New York trading hours. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
