{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eafd2e-7504-4939-aa0f-e5453400b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib # For saving the model\n",
    "\n",
    "# 1. Load the Vetoed Dataset\n",
    "# This has features (RSI, etc.) and Safety Labels (0 for NFP/Risky days)\n",
    "df = pd.read_parquet(\"../data/EURUSD_D1_Ready_for_XGBoost_Vetoed.parquet\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows.\")\n",
    "\n",
    "# 2. Prepare X (Features) and y (Target)\n",
    "# We drop columns that the model can't see or shouldn't use (like 'open', 'high', 'close')\n",
    "# We only want the calculated indicators.\n",
    "features_to_drop = ['open', 'high', 'low', 'close', 'tick_volume', 'spread', 'atr', 'label', 'real_volume']\n",
    "# Note: We keep 'label' as y, but drop it from X.\n",
    "\n",
    "X = df.drop(columns=features_to_drop, errors='ignore')\n",
    "y = df['label']\n",
    "\n",
    "# Remap labels for XGBoost\n",
    "# XGBoost expects classes to be [0, 1, 2].\n",
    "# Our labels are [-1, 0, 1]. Let's map them:\n",
    "# -1 (Sell) -> 0\n",
    "#  0 (Wait) -> 1\n",
    "#  1 (Buy)  -> 2\n",
    "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
    "y_mapped = y.map(label_mapping)\n",
    "\n",
    "print(f\"Features used ({len(X.columns)}): {X.columns.tolist()}\")\n",
    "\n",
    "# 3. Time Series Split (The \"No Cheating\" Split)\n",
    "# We split by TIME, not randomly.\n",
    "# Train: First 80% of data (Past)\n",
    "# Test: Last 20% of data (Future relative to train)\n",
    "split_point = int(len(df) * 0.80)\n",
    "\n",
    "X_train = X.iloc[:split_point]\n",
    "y_train = y_mapped.iloc[:split_point]\n",
    "\n",
    "X_test = X.iloc[split_point:]\n",
    "y_test = y_mapped.iloc[split_point:]\n",
    "\n",
    "print(f\"\\nTraining on {len(X_train)} days (Past).\")\n",
    "print(f\"Testing on {len(X_test)} days (Future).\")\n",
    "\n",
    "# 4. Initialize and Train XGBoost\n",
    "# We use 'multi:softprob' because we have 3 classes (Sell, Wait, Buy)\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,      # Number of \"trees\" (decisions)\n",
    "    learning_rate=0.05,    # Speed of learning (Lower = slower but more precise)\n",
    "    max_depth=4,           # Complexity of trees (3-5 is good to prevent overfitting)\n",
    "    objective='multi:softprob', \n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    subsample=0.8,         # Use 80% of data per tree (adds randomness/robustness)\n",
    "    colsample_bytree=0.8,  # Use 80% of features per tree\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ§  Training Supervisor Model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ… Training Complete.\")\n",
    "\n",
    "# 5. Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6. Evaluation\n",
    "# We need to map predictions back to our human-readable labels (-1, 0, 1)\n",
    "# Inverse map: 0->-1, 1->0, 2->1\n",
    "inverse_map = {0: -1, 1: 0, 2: 1}\n",
    "y_test_human = y_test.map(inverse_map)\n",
    "y_pred_human = pd.Series(y_pred).map(inverse_map)\n",
    "\n",
    "print(\"\\n--- CLASSIFICATION REPORT ---\")\n",
    "# This tells us: \"When the model said BUY, how often was it right?\" (Precision)\n",
    "print(classification_report(y_test_human, y_pred_human))\n",
    "\n",
    "# 7. Confusion Matrix Visualization\n",
    "cm = confusion_matrix(y_test_human, y_pred_human, labels=[-1, 0, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Sell', 'Wait', 'Buy'], yticklabels=['Sell', 'Wait', 'Buy'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Supervisor Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 8. Feature Importance (What did the model learn?)\n",
    "xgb.plot_importance(model, importance_type='weight', max_num_features=10)\n",
    "plt.title(\"Top 10 Features Used by Supervisor\")\n",
    "plt.show()\n",
    "\n",
    "# 9. Save the Brain\n",
    "# We save it so we can load it later for the Backtest and Live Bot\n",
    "model_filename = \"../models/supervisor_xgb.joblib\"\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"ðŸ’¾ Model saved to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
