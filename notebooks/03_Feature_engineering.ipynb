{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531b8914-d693-46e1-ba2c-13d44af3d7fb",
   "metadata": {},
   "source": [
    "### Focus: The \"Kitchen Sink\" (Aggressive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a9a70-06a4-4e27-9c44-eb10ce83363f",
   "metadata": {},
   "source": [
    "### 1.Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a21588-fb3b-497b-8aee-8c3369bbf901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data\\triple_barrier_16h.parquet...\n",
      "Initial Shape: (9301, 12)\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. CONFIGURATION\n",
    "# choosing 16 as it had the most well balanced dataset\n",
    "INPUT_FILENAME = \"triple_barrier_16h.parquet\" \n",
    "INPUT_PATH = os.path.join('../data', INPUT_FILENAME)\n",
    "OUTPUT_FILENAME = \"engineered_features_16h.parquet\"\n",
    "OUTPUT_PATH = os.path.join('../data', OUTPUT_FILENAME)\n",
    "\n",
    "# 2. LOAD DATA\n",
    "print(f\"Loading data from {INPUT_PATH}...\")\n",
    "df = pd.read_parquet(INPUT_PATH)\n",
    "\n",
    "# Ensure index is datetime\n",
    "if not isinstance(df.index, pd.DatetimeIndex):\n",
    "    # if not then simply convert it\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "print(f\"Initial Shape: {df.shape}\")\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7706b-800b-4270-b626-8d8b0dfcb6e2",
   "metadata": {},
   "source": [
    "### 2: Time Standardization (UTC+2 -> UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70038322-9ac1-4452-92db-dac98945b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting time from UTC+2 to UTC...\n",
      "New start time (UTC): 2020-01-06 06:00:00\n",
      "New end time (UTC): 2025-12-24 02:00:00\n"
     ]
    }
   ],
   "source": [
    "# 1. STANDARDIZE TIMEZONE\n",
    "# Data is UTC+2 (Broker Time). We subtract 2 hours to get true UTC.\n",
    "print(\"Shifting time from UTC+2 to UTC...\")\n",
    "\n",
    "# this is a fancy operation to remove 2 hours and hence convert the timeframt to utc\n",
    "df.index = df.index - pd.Timedelta(hours=2)\n",
    "\n",
    "# Verify the shift (Optional check)\n",
    "# If it was 10:00 Broker time, it should now be 08:00 UTC (London Open)\n",
    "print(f\"New start time (UTC): {df.index[0]}\")\n",
    "print(f\"New end time (UTC): {df.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d7f93-abdc-4ef3-9d31-c6eca1cb6845",
   "metadata": {},
   "source": [
    "### 3. Aggressive Technical & Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7582d3-cf7d-4115-bc14-cf00b6c94f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features...\n",
      "Spread features added.\n",
      "Volume features added using column: tick_volume\n",
      "Feature Engineering Complete.\n",
      "Dropped 200 rows (warmup).\n",
      "Final Feature Count: 53\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to work on like a nroaml person\n",
    "df_feat = df.copy()\n",
    "\n",
    "print(\"Generating features...\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. TIME & SESSION CONTEXT\n",
    "# ==========================================\n",
    "# Cyclical Time (Clock Coordinates)\n",
    "\n",
    "\n",
    "# We use Sine and Cosine to map the hours onto a circle. Now,\n",
    "# 11 PM and Midnight are mathematically close to each other\n",
    "\n",
    "df_feat['hour_sin'] = np.sin(2 * np.pi * df_feat.index.hour / 24)\n",
    "df_feat['hour_cos'] = np.cos(2 * np.pi * df_feat.index.hour / 24)\n",
    "df_feat['day_sin'] = np.sin(2 * np.pi * df_feat.index.dayofweek / 7)\n",
    "df_feat['day_cos'] = np.cos(2 * np.pi * df_feat.index.dayofweek / 7)\n",
    "\n",
    "# Session Booleans (Based on UTC)\n",
    "h = df_feat.index.hour\n",
    "df_feat['sess_london'] = ((h >= 7) & (h <= 16)).astype(int)\n",
    "df_feat['sess_ny'] = ((h >= 12) & (h <= 21)).astype(int)\n",
    "df_feat['sess_tokyo'] = ((h >= 0) & (h <= 9)).astype(int)\n",
    "df_feat['sess_sydney'] = ((h >= 21) | (h <= 6)).astype(int) # Wraps midnight\n",
    "\n",
    "# Critical Overlaps & Zones\n",
    "df_feat['sess_london_ny'] = (df_feat['sess_london'] & df_feat['sess_ny']).astype(int)\n",
    "df_feat['sess_tokyo_london'] = (df_feat['sess_tokyo'] & df_feat['sess_london']).astype(int)\n",
    "\n",
    "# The US banks are closed, and Tokyo hasn't opened fully. Spreads widen, and moves are often fake.\n",
    "df_feat['sess_dead_zone'] = ((h >= 21) | (h == 0)).astype(int) # Late NY / Early Syd\n",
    "\n",
    "# The market literally goes to lunch. Volume drops to zero.\n",
    "df_feat['sess_asian_lunch'] = ((h >= 3) & (h <= 4)).astype(int) # Low Volatility\n",
    "\n",
    "# ==========================================\n",
    "# 2. MARKET MICROSTRUCTURE (Spread & Vol)\n",
    "# ==========================================\n",
    "# Spread Features (Liquidity Risk)\n",
    "if 'spread' in df_feat.columns:\n",
    "    # Normalize spread by price (e.g., 0.0001 / 1.1000)\n",
    "    df_feat['spread_pct'] = df_feat['spread'] / df_feat['close']\n",
    "    # Spread Shock: Is spread currently 2x or 3x the average? (News Event Detector)\n",
    "    df_feat['spread_shock'] = df_feat['spread'] / df_feat['spread'].rolling(20).mean()\n",
    "    print(\"Spread features added.\")\n",
    "\n",
    "\n",
    "# Volume Features (Activity)\n",
    "vol_col = 'tick_volume' if 'tick_volume' in df_feat.columns else 'volume' if 'volume' in df_feat.columns else None\n",
    "\n",
    "if vol_col:\n",
    "\n",
    "    # Price moves up + Low Volume: The car is coasting uphill. It will likely roll back (False Breakout).\n",
    "    df_feat['vol_rel'] = df_feat[vol_col] / df_feat[vol_col].rolling(20).mean()\n",
    "    \n",
    "    # Force volume stationarity (Rate of Change)\n",
    "    df_feat['vol_roc'] = df_feat[vol_col].pct_change()\n",
    "    print(f\"Volume features added using column: {vol_col}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. VOLATILITY & STATS\n",
    "# ==========================================\n",
    "# Bollinger Bands\n",
    "sma_20 = df_feat['close'].rolling(20).mean()\n",
    "std_20 = df_feat['close'].rolling(20).std()\n",
    "bb_upper = sma_20 + (std_20 * 2)\n",
    "bb_lower = sma_20 - (std_20 * 2)\n",
    "\n",
    "# o measure if the market is \"nervous\" (volatile) or \"calm\", \n",
    "# and if price is \"stretched\" (likely to snap back).\n",
    "df_feat['bb_width'] = (bb_upper - bb_lower) / sma_20 # Squeeze/Expand\n",
    "df_feat['bb_pos'] = (df_feat['close'] - bb_lower) / (bb_upper - bb_lower) # Position\n",
    "\n",
    "\n",
    "\n",
    "# Rolling Distribution Shape (The \"Aggressive\" Stats)\n",
    "# Intuition (The Shape of Danger):\n",
    "\n",
    "for window in [20, 50]:\n",
    "    # Is the market crashing up or crashing down?\n",
    "    df_feat[f'roll_skew_{window}'] = df_feat['close'].rolling(window).skew()\n",
    "    # High kurtosis means the market is jumpy and dangerous.\n",
    "    df_feat[f'roll_kurt_{window}'] = df_feat['close'].rolling(window).kurt()\n",
    "\n",
    "# ATR % (if ATR exists from labelling)\n",
    "if 'atr' in df_feat.columns:\n",
    "    df_feat['atr_pct'] = df_feat['atr'] / df_feat['close']\n",
    "\n",
    "# ==========================================\n",
    "# 4. MOMENTUM & TREND (Stationary)\n",
    "# ==========================================\n",
    "# RSI\n",
    "# Intuition (The Speedometer): How fast is price changing? If RSI > 70, the engine is redlining.\n",
    "\n",
    "for window in [7, 14, 21]:\n",
    "    delta = df_feat['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    df_feat[f'rsi_{window}'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# MACD\n",
    "ema_12 = df_feat['close'].ewm(span=12, adjust=False).mean()\n",
    "ema_26 = df_feat['close'].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "# \"Are the short-term and long-term trends agreeing or fighting?\"\n",
    "df_feat['macd_hist'] = (ema_12 - ema_26) - (ema_12 - ema_26).ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Distance from Moving Averages (Trend Strength)\n",
    "for period in [20, 50, 100, 200]:\n",
    "    ma = df_feat['close'].rolling(period).mean()\n",
    "    df_feat[f'dist_sma_{period}'] = (df_feat['close'] - ma) / ma\n",
    "    df_feat[f'slope_sma_{period}'] = ma.diff()\n",
    "\n",
    "# ==========================================\n",
    "# 5. LAGS (Memory)\n",
    "# ==========================================\n",
    "# Log returns of previous candles\n",
    "for lag in [1, 2, 3, 5, 8, 13]:\n",
    "    df_feat[f'log_ret_lag_{lag}'] = np.log(df_feat['close'] / df_feat['close'].shift(lag))\n",
    "\n",
    "# Cleanup\n",
    "# Drop rows with NaN (Warmup period for 200 SMA)\n",
    "original_len = len(df_feat)\n",
    "df_feat.dropna(inplace=True)\n",
    "\n",
    "print(\"Feature Engineering Complete.\")\n",
    "print(f\"Dropped {original_len - len(df_feat)} rows (warmup).\")\n",
    "print(f\"Final Feature Count: {df_feat.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e75c15-e8b8-4a34-876e-75692bce6b7d",
   "metadata": {},
   "source": [
    "### Save Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804d7b1-0112-4d04-affd-c1cb37869969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save to Parquet\n",
    "print(f\"Saving processed data to {OUTPUT_PATH}...\")\n",
    "df_feat.to_parquet(OUTPUT_PATH, index=True)\n",
    "\n",
    "# 2. Sanity Check: Inspect the Columns\n",
    "print(\"\\n--- Feature List ---\")\n",
    "print(df_feat.columns.tolist())\n",
    "\n",
    "print(\"\\n--- Sample Data (Last 5 rows) ---\")\n",
    "df_feat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c56f67-2575-4c01-b673-5e6c6766d4c4",
   "metadata": {},
   "source": [
    "### to be tried later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7093fa-0fb8-4ee2-ac51-799dca61d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. SETUP\n",
    "# Load your dataset (assuming it is named 'df' from the previous steps)\n",
    "# If reloading: df = pd.read_parquet('../data/engineered_features_16h.parquet')\n",
    "\n",
    "# Ensure Volume exists (Backups for different naming conventions)\n",
    "if 'tick_volume' in df.columns:\n",
    "    df['volume'] = df['tick_volume']\n",
    "elif 'Volume' in df.columns:\n",
    "    df['volume'] = df['Volume']\n",
    "\n",
    "# ==========================================\n",
    "# 2. DEFINING THE \"GOLD STANDARD\" STRATEGY\n",
    "# ==========================================\n",
    "# We only calculate what adds unique information.\n",
    "\n",
    "RefinedStrategy = ta.Strategy(\n",
    "    name=\"Refined_ML_Strategy\",\n",
    "    description=\"Non-redundant, stationary-focused indicators\",\n",
    "    ta=[\n",
    "        # --- TREND STRENGTH (Is the market moving?) ---\n",
    "        {\"kind\": \"adx\", \"length\": 14},   # Trend Strength\n",
    "        {\"kind\": \"aroon\", \"length\": 25}, # Trend Start/End\n",
    "        \n",
    "        # --- BASELINES (To measure distance from) ---\n",
    "        {\"kind\": \"ema\", \"length\": 50},\n",
    "        {\"kind\": \"ema\", \"length\": 200},\n",
    "        {\"kind\": \"psar\"},                # Parabolic SAR (Trailing Stop proxy)\n",
    "        \n",
    "        # --- MOMENTUM (Cyclical & Velocity) ---\n",
    "        {\"kind\": \"rsi\", \"length\": 14},\n",
    "        {\"kind\": \"cci\", \"length\": 20},   # Cyclical nature\n",
    "        {\"kind\": \"macd\"},                # Trend Velocity\n",
    "        {\"kind\": \"stoch\"},               # Overbought/Oversold\n",
    "        {\"kind\": \"willr\"},               # Williams %R (Fast momentum)\n",
    "        \n",
    "        # --- VOLATILITY (Regime) ---\n",
    "        {\"kind\": \"bbands\", \"length\": 20}, # Volatility Squeeze\n",
    "        {\"kind\": \"atr\", \"length\": 14},    # Normalizer\n",
    "        {\"kind\": \"kc\"},                   # Keltner Channels (Trend pullbacks)\n",
    "\n",
    "        # --- VOLUME (Confirmation) ---\n",
    "        {\"kind\": \"obv\"},      # Cumulative Flow\n",
    "        {\"kind\": \"cmf\"},      # Institutional Flow\n",
    "        {\"kind\": \"mfi\"},      # Momentum of Volume\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Running Refined Strategy...\")\n",
    "df.ta.strategy(RefinedStrategy, cores=0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. CRITICAL: STATIONARIZING FEATURES\n",
    "# ==========================================\n",
    "# Converting \"Price Levels\" to \"Relative Percentages\"\n",
    "\n",
    "print(\"Post-processing features for Stationarity...\")\n",
    "\n",
    "# A. Distances to Averages (Instead of raw EMA values)\n",
    "# \"Price is 2% above the 200 EMA\" is better than \"EMA is 1.0500\"\n",
    "df['dist_ema_50'] = (df['close'] - df['EMA_50']) / df['EMA_50']\n",
    "df['dist_ema_200'] = (df['close'] - df['EMA_200']) / df['EMA_200']\n",
    "\n",
    "# B. Distance to Parabolic SAR (Stop Loss proxy)\n",
    "# PSARs and Psarl are the columns created by pandas_ta\n",
    "# We combine them into one distance metric\n",
    "psar_col = df['PSARl_0.02_0.2'].fillna(df['PSARs_0.02_0.2'])\n",
    "df['dist_psar'] = (df['close'] - psar_col) / df['close']\n",
    "\n",
    "# C. Bollinger Band Features\n",
    "# Bandwidth is already stationary (Width / Mean)\n",
    "# %B is already stationary (Position)\n",
    "# Rename for clarity if needed, but pandas_ta names them BBP_20_2.0 and BBB_20_2.0\n",
    "\n",
    "# D. Keltner Channel Position\n",
    "# Where is price relative to the Keltner Channel?\n",
    "# (Close - Lower) / (Upper - Lower)\n",
    "kc_upper = df['KCqe_20_2.0'] # Upper channel\n",
    "kc_lower = df['KCle_20_2.0'] # Lower channel\n",
    "df['kc_pos'] = (df['close'] - kc_lower) / (kc_upper - kc_lower)\n",
    "\n",
    "# ==========================================\n",
    "# 4. DROPPING RAW PRICE COLUMNS\n",
    "# ==========================================\n",
    "# We used EMA_50 and PSAR to calculate distances. \n",
    "# Now we remove the raw price columns so the model doesn't overfit to them.\n",
    "\n",
    "cols_to_drop = [\n",
    "    'EMA_50', 'EMA_200', \n",
    "    'PSARl_0.02_0.2', 'PSARs_0.02_0.2', 'PSARaf_0.02_0.2', 'PSARr_0.02_0.2',\n",
    "    'KCbe_20_2.0', 'KCqe_20_2.0', 'KCle_20_2.0' # Raw Keltner levels\n",
    "]\n",
    "\n",
    "# Only drop if they exist\n",
    "df.drop(columns=[c for c in cols_to_drop if c in df.columns], inplace=True)\n",
    "\n",
    "# Drop warmup rows (NaNs)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(f\"Final Feature Engineering Complete.\")\n",
    "print(f\"Final Shape: {df.shape}\")\n",
    "\n",
    "# Save\n",
    "OUTPUT_PATH = os.path.join('../data', \"engineered_features_final.parquet\")\n",
    "df.to_parquet(OUTPUT_PATH)\n",
    "print(f\"Saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nFinal Feature List:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a88c9-1f0e-4583-afea-a4a113b58902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Trend Indicators (Baselines)\n",
    "# These indicators identify the general direction of the market and help traders \"follow the trend\". \n",
    "# Simple Moving Average (SMA): The average price over a set number of periods.\n",
    "# Exponential Moving Average (EMA): Similar to SMA but weights recent prices more heavily.\n",
    "# Weighted Moving Average (WMA): Assigns heavier weight to the most recent data points.\n",
    "# Hull Moving Average (HMA): Designed to reduce lag and improve smoothness.\n",
    "# Kaufman Adaptive Moving Average (KAMA): Adjusts its sensitivity based on market noise.\n",
    "# Ichimoku Cloud (Kinko Hyo): A comprehensive system showing trend, support, and resistance.\n",
    "# Parabolic SAR (Stop and Reverse): Uses dots to indicate potential trend reversals.\n",
    "# Average Directional Index (ADX): Measures the strength of a trend.\n",
    "# Aroon Indicator: Identifies when a trend is starting or changing.\n",
    "# Aroon Oscillator: Measures the difference between Aroon Up and Aroon Down.\n",
    "# Linear Regression Trendline: A straight line that best fits a set of price data.\n",
    "# Double Exponential Moving Average (DEMA): Further reduces lag from standard EMAs.\n",
    "# Triple Exponential Moving Average (TEMA): Uses triple smoothing to minimize lag.\n",
    "# Supertrend: A trend-following indicator based on ATR.\n",
    "# ZigZag: Filters out smaller price movements to show significant trends.\n",
    "# Schaff Trend Cycle (STC): Combines MACD with a stochastic for faster trend signals.\n",
    "# TRIX: A triple-smoothed exponential oscillator for trend identification.\n",
    "# Detrended Price Oscillator (DPO): Removes trend to highlight short-term cycles.\n",
    "# Alligator (Bill Williams): Uses three smoothed moving averages to identify trends.\n",
    "# Gann Fans/Gann Lines: Based on geometric angles of price and time. \n",
    "\n",
    "# 2. Momentum Indicators (Oscillators)\n",
    "# These measure the speed of price movements and identify overbought or oversold conditions.\n",
    "# 21. Relative Strength Index (RSI): Ranges 0-100; signals overbought (>70) or oversold (<30).\n",
    "# 22. Stochastic Oscillator: Compares closing price to its range over time.\n",
    "# 23. MACD (Moving Average Convergence Divergence): Shows the relationship between two EMAs.\n",
    "# 24. Commodity Channel Index (CCI): Identifies cyclical trends and reversals.\n",
    "# 25. Williams %R: Shows where the current price is relative to the highest high.\n",
    "# 26. Awesome Oscillator (AO): Measures market momentum using 34 and 5-period SMAs.\n",
    "# 27. Momentum Indicator: Measures the rate of change of prices.\n",
    "# 28. Rate of Change (ROC): Calculates the percentage change in price between periods.\n",
    "# 29. Money Flow Index (MFI): Volume-weighted version of RSI.\n",
    "# 30. Relative Vigor Index (RVI): Measures the strength of a trend by comparing closing prices.\n",
    "# 31. Stochastic RSI: A stochastic applied to RSI values for increased sensitivity.\n",
    "# 32. Ultimate Oscillator: Uses three different timeframes to reduce false signals.\n",
    "# 33. Chande Momentum Oscillator (CMO): Calculates momentum based on unsmoothed data.\n",
    "# 34. Gator Oscillator: Derived from the Alligator indicator to show trend changes.\n",
    "# 35. DeMarker (DeM): Compares most recent maximum and minimum prices.\n",
    "# 36. True Strength Index (TSI): A double-smoothed momentum oscillator.\n",
    "# 37. Vortex Indicator: Two lines (+VI and -VI) that identify the start of a new trend.\n",
    "# 38. Fisher Transform: Transforms prices into a Gaussian normal distribution.\n",
    "# 39. Center of Gravity Oscillator: Identifies major turning points without lag.\n",
    "# 40. Percentage Price Oscillator (PPO): Similar to MACD but shown in percentages. \n",
    "\n",
    "# 3. Volatility Indicators\n",
    "# These measure how far price stretches from its mean, helping with risk management and breakout detection.\n",
    "# 41. Bollinger Bands: A moving average with two standard deviation bands.\n",
    "# 42. Average True Range (ATR): Measures the average range of price movement.\n",
    "# 43. Standard Deviation: Measures how spread out price data is from the mean.\n",
    "# 44. Keltner Channels: Volatility-based envelopes set above/below an EMA.\n",
    "# 45. Donchian Channels: Shows the highest high and lowest low over a period.\n",
    "# 46. Envelopes: Two moving averages set at a fixed percentage above and below price.\n",
    "# 47. Chaikin Volatility: Measures the difference between high and low prices.\n",
    "# 48. Bollinger Bandwidth: Measures the distance between upper and lower Bollinger Bands.\n",
    "# 49. STARC Bands: Combines moving averages and ATR to create volatility channels.\n",
    "# 50. Ulcer Index: Measures \"stress\" by analyzing the depth and duration of price drops.\n",
    "# 51. Relative Volatility Index (RVI): Measures the direction of volatility.\n",
    "# 52. Choppiness Index: Determines if the market is trending or \"choppy\".\n",
    "# 53. Mass Index: Predicts reversals by measuring the narrowing/widening of price ranges.\n",
    "# 54. Historical Volatility (HV): Measures the past standard deviation of an asset. \n",
    "    \n",
    "#     4. Volume & Support/Resistance Indicators\n",
    "# These measure market participation and key price levels.\n",
    "# 55. On-Balance Volume (OBV): Relates volume to price change to confirm trends.\n",
    "# 56. Accumulation/Distribution (A/D): Measures the cumulative flow of money.\n",
    "# 57. Chaikin Money Flow (CMF): Measures the amount of Money Flow Volume over a period.\n",
    "# 58. Volume Weighted Average Price (VWAP): Average price weighted by total volume.\n",
    "# 59. Pivot Points (Standard): Key levels calculated from the previous day's H/L/C.\n",
    "# 60. Fibonacci Retracements: Horizontal lines based on Fibonacci ratios to find support.\n",
    "# 61. Volume Profile: Shows volume traded at specific price levels.\n",
    "# 62. Ease of Movement (EOM): Relates price change to volume.\n",
    "# 63. Money Flow Ratio: Compares positive and negative money flow.\n",
    "# 64. Negative Volume Index (NVI): Focuses on days where volume decreased.\n",
    "# 65. Positive Volume Index (PVI): Focuses on days where volume increased.\n",
    "# 66. Price Volume Trend (PVT): Cumulative volume that adds a percentage of the day's volume.\n",
    "# 67. Trade Volume Index (TVI): Used to determine whether an asset is being accumulated.\n",
    "# 68. Market Profile: Visualizes price and volume over time (TPO).\n",
    "# 69. Balance of Power (BOP): Measures the strength of buyers vs. sellers.\n",
    "# 70. Camarilla Pivot Points: A variation of pivots providing tighter support/resistance.\n",
    "# 71. Woodieâ€™s Pivot Points: Weighted differently to emphasize recent price action.\n",
    "# 72. Fibonacci Extensions: Projects potential future profit-taking levels.\n",
    "# 73. Elder Force Index: Combines price movement and volume to measure trend power.\n",
    "# 74. Vortex Indicator (VI): Identifies the start of a trend based on high/low distance.\n",
    "# 75. Chaikin Oscillator: Applies MACD to the Accumulation/Distribution line.\n",
    "# 76. Force Index: Uses price, volume, and time to identify trend strength.\n",
    "# 77. Klinger Oscillator: Compares volume flowing through an asset with price\n",
    "\n",
    "# 5. Specialized & Hybrid Indicators\n",
    "# Fractals (Bill Williams): Arrows that highlight local high and low points.\n",
    "# Heiken Ashi: Specialized candlesticks that filter market noise.\n",
    "# TD Sequential: Identifies trend exhaustion and potential price flips.\n",
    "# Murrey Math Lines: Support/resistance levels based on Gann's theory.\n",
    "# Psychological Line: Measures the ratio of rising days to total days.\n",
    "# Volume Rate of Change (VROC): Percentage change in volume.\n",
    "# Typical Price: (High + Low + Close) / 3.\n",
    "# Median Price: (High + Low) / 2.\n",
    "# Adaptive Lagging Line: Follows price but smooths out data without excessive lag.\n",
    "# Trend Intensity Index (TII): Measures the strength of a trend.\n",
    "# Rainbow Moving Average: Multiple MAs used together to show trend maturity.\n",
    "# Linear Regression Slope: Measures the rate of change of a linear regression line.\n",
    "# CVI (Chart Volatility Index): A custom measure of intraday volatility.\n",
    "# Gpivot Ressup: Dynamic support and resistance pivot variation.\n",
    "# DMI (Directional Movement Index): Consists of +DI and -DI lines.\n",
    "# TMA (Triangular Moving Average): Double-smoothed version of the SMA.\n",
    "# QQE (Quantitative Qualitative Estimation): Smother RSI-based indicator.\n",
    "# RSX (Relative Strength Index smoothed): A noise-free version of RSI.\n",
    "# ATR Trailing Stop: A stop-loss level that moves with the price.\n",
    "# Connors RSI: Combines RSI, Up/Down Length, and Rate of Change.\n",
    "# Forex Sentiment: Measures the percentage of long vs. short retail positions.\n",
    "# Currency Strength Meter: Compares one currency's performance against all others.\n",
    "# Market Sessions Indicator: Highlights Asian, London, and New York trading hours. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
