{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42124c88-3843-4230-a7a0-c3b365d0b957",
   "metadata": {},
   "source": [
    "### Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0aebc53-37c5-4fe3-9196-24590a45259a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting M1 Extraction for EURUSD...\n",
      "‚è≥ Fetching 2020...\n",
      "‚è≥ Fetching 2021...\n",
      "‚è≥ Fetching 2022...\n",
      "‚è≥ Fetching 2023...\n",
      "‚è≥ Fetching 2024...\n",
      "‚è≥ Fetching 2025...\n",
      "‚è≥ Fetching 2026...\n",
      "‚ö†Ô∏è No data for 2026\n",
      "‚úÖ Success! Saved 2223168 rows to ../data\\EURUSD_M1_Raw.parquet\n",
      "                        open     high      low    close  tick_volume\n",
      "time                                                                \n",
      "2025-12-31 23:54:00  1.17459  1.17460  1.17457  1.17458            7\n",
      "2025-12-31 23:55:00  1.17463  1.17463  1.17453  1.17455           18\n",
      "2025-12-31 23:56:00  1.17455  1.17455  1.17454  1.17454            2\n",
      "2025-12-31 23:57:00  1.17454  1.17455  1.17453  1.17454           11\n",
      "2025-12-31 23:58:00  1.17453  1.17453  1.17453  1.17453            1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 01_data_collection_m1.ipynb\n",
    "\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "\n",
    "# --- CONFIG ---\n",
    "SYMBOL = \"EURUSD\"\n",
    "TIMEFRAME = mt5.TIMEFRAME_M1  # <--- CRITICAL: Fetching M1, not H1\n",
    "START_YEAR = 2020\n",
    "END_YEAR = 2026\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "# --- INIT ---\n",
    "# Tries to connect to your MT5 terminal\n",
    "if not mt5.initialize():\n",
    "    print(f\"‚ùå Initialize failed: {mt5.last_error()}\")\n",
    "    quit()\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# --- CHUNK FETCHING FUNCTION ---\n",
    "def fetch_data_in_chunks(symbol, timeframe, start_year, end_year):\n",
    "    all_dfs = []\n",
    "    \n",
    "    # Iterate through years to avoid MT5 timeout\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        \n",
    "        # Start (Jan 1) and end (Dec 31) of the current year in the loop\n",
    "        t_start = datetime(year, 1, 1, tzinfo=timezone.utc)\n",
    "        t_end = datetime(year, 12, 31, 23, 59, tzinfo=timezone.utc)\n",
    "        \n",
    "        # Don't fetch future\n",
    "        if t_start > datetime.now(timezone.utc):\n",
    "            break\n",
    "        if t_end > datetime.now(timezone.utc):\n",
    "            t_end = datetime.now(timezone.utc)\n",
    "\n",
    "        print(f\"‚è≥ Fetching {year}...\")\n",
    "        rates = mt5.copy_rates_range(symbol, timeframe, t_start, t_end)\n",
    "        \n",
    "        if rates is not None and len(rates) > 0:\n",
    "            df_chunk = pd.DataFrame(rates)\n",
    "            df_chunk['time'] = pd.to_datetime(df_chunk['time'], unit='s')\n",
    "            all_dfs.append(df_chunk)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No data for {year}\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        return None\n",
    "        \n",
    "    # Combine all chunks\n",
    "    final_df = pd.concat(all_dfs).drop_duplicates(subset='time').sort_values('time')\n",
    "    final_df.set_index('time', inplace=True)\n",
    "    return final_df[['open', 'high', 'low', 'close', 'tick_volume']]\n",
    "\n",
    "# --- EXECUTION ---\n",
    "print(f\"üöÄ Starting M1 Extraction for {SYMBOL}...\")\n",
    "df_m1 = fetch_data_in_chunks(SYMBOL, TIMEFRAME, START_YEAR, END_YEAR)\n",
    "\n",
    "if df_m1 is not None:\n",
    "    # Save as Parquet (Much faster/smaller than CSV for M1 data)\n",
    "    save_path = os.path.join(DATA_DIR, f\"{SYMBOL}_M1_Raw.parquet\")\n",
    "    df_m1.to_parquet(save_path)\n",
    "    print(f\"‚úÖ Success! Saved {len(df_m1)} rows to {save_path}\")\n",
    "    print(df_m1.tail())\n",
    "else:\n",
    "    print(\"‚ùå Failed to fetch data.\")\n",
    "\n",
    "mt5.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdaef3-82c9-4bc2-ad86-da7428af7857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
